{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 10 rows\n",
      "OK rows: 0010, Rejected rows: 0000\n"
     ]
    }
   ],
   "source": [
    "# Read file into json rows\n",
    "\n",
    "import json\n",
    "\n",
    "def run(file_name:str, print_lines:bool=False) -> None:\n",
    "    \"\"\"\n",
    "    From JSON row file read each row\n",
    "\n",
    "    Args:\n",
    "        file_name (str): file path to read\n",
    "        print_lines (bool): print lines from file to console.\n",
    "    \"\"\"\n",
    "    # track the row count\n",
    "    line_num = 1        # Current line number\n",
    "    ok_count = 0        # Rows that didn't return an error\n",
    "    reject_count = 0    # Rows that did return an error\n",
    "    with open(file_name, \"r\") as json_file:\n",
    "        for line in json_file:\n",
    "            try:\n",
    "                # Read lines into a dict\n",
    "                row = json.loads(line.strip())\n",
    "                # Print lines\n",
    "                if print_lines:\n",
    "                    print(f\"[{line_num:04d} [OK]: {row}\")\n",
    "                # Line count update\n",
    "                ok_count += 1\n",
    "            except Exception as err:\n",
    "                # print row with error\n",
    "                print(f\"[{line_num:04d}][ERROR:] {str(err)}, [DATA]: {row}\")\n",
    "                reject_count += 1\n",
    "            finally:\n",
    "                # Update line count regardless if exception or not\n",
    "                line_num += 1\n",
    "        # Print line count summary\n",
    "    print(f\"Read {line_num - 1} rows\")\n",
    "    print(f\"OK rows: {ok_count:04d}, Rejected rows: {reject_count:04d}\") \n",
    "\n",
    "# Call the function for a test\n",
    "file_path = \"./data/profiles2.json\"\n",
    "run(file_path, print_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add meta data columns\n",
    "\n",
    "from datetime import datetime\n",
    "import shortuuid\n",
    "\n",
    "# get a unique ID for this ETL batch (script)\n",
    "BATCH_ID = shortuuid.uuid()\n",
    "\n",
    "def add_metadata(row:dict) -> None:\n",
    "    \"\"\"\n",
    "    Adds ETL metadata columns to a row. Follwing metadata columns \n",
    "    are added:\n",
    "        - modified_timestamp: current datetime\n",
    "        - batch_id: unique ETL batch_id\n",
    "        - tags: a key/value dict to store various data tags\n",
    "        - tags.errors: a list of error message encountered while processing this row\n",
    "\n",
    "    Args:\n",
    "        row (dict): data row\n",
    "    \"\"\"\n",
    "    global BATCH_ID\n",
    "    now_utc = datetime.utcnow()\n",
    "    # add timestamps for when we have processed this row\n",
    "    row[\"modified_timestamp\"] = now_utc\n",
    "    # add the ETL (script) batch_id\n",
    "    row[\"batch_id\"] = BATCH_ID\n",
    "    # a series of additional processing tags \n",
    "    row[\"tags\"] = {\n",
    "        # other tags can go here, for example:\n",
    "        \"security_level\": \"high\",\n",
    "        \"allow_user_groups\": [\"admin\",]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data quality checks\n",
    "# -schema check\n",
    "# -null check\n",
    "\n",
    "REQUIRED_SCHEMA_FIELDS = {'uid','name', 'gender', 'email', 'birthdate', 'salary', 'credit_score', 'active', 'modified_timestamp'}\n",
    "\n",
    "def schema_check(row:dict, fields=REQUIRED_SCHEMA_FIELDS) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if all required fields (dict) are present in a dict or JSON row. Any \n",
    "    missing fields will cause a KeyError exception.\n",
    "\n",
    "    Args:\n",
    "        row (dict): data row\n",
    "        fields (set, optional): set of required required fields. Defaults to NOT_NULL_FIELDS.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all fields (keys) are present\n",
    "\n",
    "    Raises:\n",
    "        KeyError: if any of the required fields (keys) are missing in row\n",
    "    \"\"\" \n",
    "    # loop thru the required fields and make sure they are all present\n",
    "    for field in fields:\n",
    "        # if this field is missing in row, raise an exception\n",
    "        if field not in row:\n",
    "            raise KeyError(f\"Missing required field: {field}\")\n",
    "    # return true if no exceptions\n",
    "    return True\n",
    "\n",
    "# default fields to check for null values\n",
    "NOT_NULL_FIELDS = {'uid','name', 'gender', 'email', 'birthdate', 'salary', 'credit_score', 'active', 'modified_timestamp'}\n",
    "\n",
    "def null_check(row:dict, fields=NOT_NULL_FIELDS) -> bool:\n",
    "    \"\"\"\n",
    "    Checks the row to NOT contain None values for any of the fields provided. \n",
    "    Any fields containing None would cause a ValueError exception.\n",
    "\n",
    "    Args:\n",
    "        row (dict): data row\n",
    "        fields (set, optional): list of dict keys to check the value for. Defaults to NOT_NULL_FIELDS.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if none of the fields contain None values\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if a field contains None\n",
    "    \"\"\"    \n",
    "    for field in fields:\n",
    "        # check to see if the value of this field is None or null\n",
    "        if row[field] is None:\n",
    "            # add an error message to this row\n",
    "            raise ValueError(f\"{field} can NOT be None or null.\")\n",
    "    # otherwise return True\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00][ERR]: uid can NOT be None or null., [DATA]: {'uid': None, 'name': 'Tara White', 'gender': 'F', 'email': 'tara.white@gmail.com', 'birthdate': '1963-08-23', 'salary': 143720.55, 'credit_score': 511, 'active': True, 'modified_timestamp': datetime.datetime(2022, 11, 17, 22, 52, 10, 987136), 'batch_id': 'PSpD8vWY3n3Wi2vqRuH6Q9', 'tags': {'security_level': 'high', 'allow_user_groups': ['admin']}}\n",
      "[05][ERR]: 'Missing required field: email', [DATA]: {'uid': 'aFVLPen3gfmFqnqJzWzWez', 'name': 'Christopher Baker', 'gender': 'M', 'birthdate': '1906-06-30', 'salary': 140941.94, 'credit_score': 515, 'active': True, 'modified_timestamp': datetime.datetime(2022, 11, 17, 22, 52, 10, 987271), 'batch_id': 'PSpD8vWY3n3Wi2vqRuH6Q9', 'tags': {'security_level': 'high', 'allow_user_groups': ['admin']}}\n",
      "[09][ERR]: salary can NOT be None or null., [DATA]: {'uid': 'bGo4GCcUkpLuZcDWFkxuAE', 'name': 'Ryan Brown', 'gender': 'M', 'email': 'ryan.brown@gmail.com', 'birthdate': '1941-04-23', 'salary': None, 'credit_score': 678, 'active': True, 'modified_timestamp': datetime.datetime(2022, 11, 17, 22, 52, 10, 987319), 'batch_id': 'PSpD8vWY3n3Wi2vqRuH6Q9', 'tags': {'security_level': 'high', 'allow_user_groups': ['admin']}}\n",
      "Read 10 rows\n",
      "OK rows: 07, Rejected rows: 03\n"
     ]
    }
   ],
   "source": [
    "# check rejects\n",
    "\n",
    "def run(file_name:str, print_lines:bool=False) -> None:\n",
    "    \"\"\"\n",
    "    Reads user profiles from a JSON row formated file.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): file path to read\n",
    "        print_lines (bool): print lines to console\n",
    "    \"\"\"\n",
    "    # keep track or row counts\n",
    "    line_num = 0            # total number of rows\n",
    "    ok_count = 0            # number of rows without errors\n",
    "    reject_count = 0        # number of rows with errors\n",
    "\n",
    "    with open(file_name, \"r\") as json_file:\n",
    "        for line in json_file:\n",
    "            try:\n",
    "                row = json.loads(line.strip())\n",
    "                # checks & transformations\n",
    "                add_metadata(row)\n",
    "                schema_check(row)\n",
    "                null_check(row)\n",
    "                if print_lines:\n",
    "                    print(f\"[{line_num:02d}][OK]: {row}\")\n",
    "                ok_count += 1\n",
    "            except Exception as err:\n",
    "                print(f\"[{line_num:02d}][ERR]: {str(err)}, [DATA]: {row}\")\n",
    "                reject_count += 1\n",
    "            finally:\n",
    "                line_num += 1\n",
    "    # print line count summary at the end\n",
    "    print(f\"Read {line_num} rows\")\n",
    "    print(f\"OK rows: {ok_count:02d}, Rejected rows: {reject_count:02d}\")\n",
    "\n",
    "\n",
    "\n",
    "# call our function to test\n",
    "filepath = \"./data/profiles2.json\"\n",
    "run(filepath, print_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transform + load\n",
    "# - parse dates\n",
    "# - generate json for rejects and ok\n",
    "\n",
    "from json import JSONEncoder\n",
    "\n",
    "\n",
    "class DatetimeEncoder(JSONEncoder):\n",
    "    \"\"\"\n",
    "    Custom JSON Encoder class to properly encode datetime fields. All other fields are encoded with \n",
    "    their default formatting. This class inherits the default json.JSONEncoder class.\n",
    "    \"\"\"\n",
    "\n",
    "    def default(self, value):\n",
    "        \"\"\"Encodes values to JSON. Adds special formatting for datetime fields.\n",
    "\n",
    "        Args:\n",
    "            value (object): field to encode\n",
    "\n",
    "        Returns:\n",
    "            object: encoded json string\n",
    "        \"\"\"\n",
    "        # check for datetime type\n",
    "        if isinstance(value, datetime):\n",
    "            # format the datetime string\n",
    "            dtfmt = \"%Y-%d-%m %H:%M:%S.%f %z\"\n",
    "            return datetime.strftime(value, dtfmt)\n",
    "        # all other data types default to the JSONEncoder parent class formatting\n",
    "        super(DatetimeEncoder, self).default(value)\n",
    "\n",
    "\n",
    "def run(file_name:str, print_lines:bool=False) -> None:\n",
    "    \"\"\"\n",
    "    Reads user profiles from a JSON row formated file.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): file path to read\n",
    "        print_lines (bool): print lines to console\n",
    "    \"\"\"\n",
    "    # keep track or row counts\n",
    "    line_num = 0            # total number of rows\n",
    "    ok_count = 0            # number of rows without errors\n",
    "    reject_count = 0        # number of rows with errors\n",
    "\n",
    "    # prepare a ok & reject file\n",
    "    # -------------------------------------\n",
    "    # add a timestamp to files\n",
    "    file_timestamp = datetime.utcnow().strftime(\"%Y%m%d\")\n",
    "    # get the file name without it's extension\n",
    "    file_name_without_extension = file_name.rpartition('.')[0]      # from the right of the string, partition by '.' and take the first partition\n",
    "    # create ok and reject file names including the timestamp\n",
    "    ok_file_name = f\"{file_name_without_extension}_{file_timestamp}_ok.json\"\n",
    "    reject_file_name = f\"{file_name_without_extension}_{file_timestamp}_reject.json\"\n",
    "    # open files for writing\n",
    "    ok_file = open(ok_file_name, \"w\", encoding=\"utf-8\")\n",
    "    reject_file = open(reject_file_name, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "    with open(file_name, \"r\") as json_file:\n",
    "        for line in json_file:\n",
    "            try:\n",
    "                row = json.loads(line.strip())\n",
    "                # checks & transformations\n",
    "                add_metadata(row)\n",
    "                schema_check(row)\n",
    "                null_check(row)\n",
    "                # write to ok file\n",
    "                json.dump(row, ok_file, cls=DatetimeEncoder)     # write the json row\n",
    "                ok_file.write(\"\\n\")         # write endline character\n",
    "\n",
    "                if print_lines:\n",
    "                    print(f\"[{line_num:04d}][OK]: {row}\")\n",
    "                ok_count += 1\n",
    "            except Exception as err:\n",
    "                # add error and line number to the json row\n",
    "                err_msg = f\"[{line_num:04d}][ERR]: {str(err)}\"\n",
    "                row[\"error\"] = err_msg\n",
    "                # write the error line to reject file\n",
    "                json.dump(row, reject_file, cls=DatetimeEncoder)\n",
    "                reject_file.write('\\n')\n",
    "                print(err_msg, row)\n",
    "                reject_count += 1\n",
    "            finally:\n",
    "                line_num += 1\n",
    "    # print line count summary at the end\n",
    "    print(f\"Read {line_num} rows\")\n",
    "    print(f\"OK rows: {ok_count:04d}, Rejected rows: {reject_count:04d}\")\n",
    "    # close files\n",
    "    ok_file.close()\n",
    "    reject_file.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ebf270603097c86092d999674f84c728027fa67fa1e770293fb80ab8ba229c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
